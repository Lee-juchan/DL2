{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smartdesignlab/SDL_teaching/blob/main/KAIST_SDL_2_Predictive_AI_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L4M5KUvgjTdi",
      "metadata": {
        "id": "L4M5KUvgjTdi"
      },
      "source": [
        "# **2. Predictive AI: CNN for Compliance Prediction**\n",
        "![CNN](https://drive.google.com/uc?id=1MwNrNUYoOpqUv1UkFedcUCLRLVu9hRb9)\n",
        "**Overview**:  \n",
        "\n",
        "1) Import libraries and define parameters.  \n",
        "2) Load and preprocess a dataset of images along with compliance labels.  \n",
        "3) Define a Convolutional Neural Network (CNN) for predicting two compliance\n",
        "values.  \n",
        "4) Train and evaluate the CNN model.  \n",
        "5) Visualize results.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VDnUc7nOjTdj",
      "metadata": {
        "id": "VDnUc7nOjTdj"
      },
      "source": [
        "## 1) Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1252602",
      "metadata": {
        "id": "e1252602"
      },
      "source": [
        "### **| Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EN2vVSCLjTdk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN2vVSCLjTdk",
        "outputId": "1edb931c-73fa-4e24-b107-951317a4b585"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import random\n",
        "\n",
        "# Device selection\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set a global seed for reproducibility\n",
        "set_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "crqchHTPjTdl",
      "metadata": {
        "id": "crqchHTPjTdl"
      },
      "source": [
        "## 2) Load and Preprocess Data\n",
        "The **`ComplianceDataset`** class:\n",
        "1. Reads a `compliance_label.csv` file.\n",
        "2. Loads images (grayscale, `PNG` format).\n",
        "3. Normalizes them to the range `[-1, 1]`.\n",
        "4. Normalizes labels `(compliance1, compliance2)` to `[0, 1]`.\n",
        "5. Returns `(image_tensor, label_tensor)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YVC2jWZajTdl",
      "metadata": {
        "id": "YVC2jWZajTdl"
      },
      "outputs": [],
      "source": [
        "class ComplianceDataset(Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        # CSV file path\n",
        "        csv_path = os.path.join(data_dir, 'compliance_label.csv')\n",
        "\n",
        "        self.indices = []\n",
        "        self.labels = []  # Will store (comp1, comp2)\n",
        "\n",
        "        with open(csv_path, 'r', encoding='utf-8') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader)  # Skip header\n",
        "            for row in reader:\n",
        "                index = int(row[0])\n",
        "                comp1 = float(row[1])\n",
        "                comp2 = float(row[2])\n",
        "                self.indices.append(index)\n",
        "                self.labels.append([comp1, comp2])\n",
        "\n",
        "        self.labels = np.array(self.labels)\n",
        "\n",
        "        # Normalize labels to [0, 1]\n",
        "        self.labels_min = self.labels.min(axis=0)\n",
        "        self.labels_max = self.labels.max(axis=0)\n",
        "        self.labels = (self.labels - self.labels_min) / (self.labels_max - self.labels_min)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        index = self.indices[idx]\n",
        "        # Image file name: inference_XXX.png\n",
        "        img_path = os.path.join(self.data_dir, f\"inference_{index:03d}.png\")\n",
        "        image = Image.open(img_path).convert('L')  # Grayscale\n",
        "        image = np.array(image, dtype=np.float32)\n",
        "\n",
        "        # Normalize image from [0, 255] to [-1, 1]\n",
        "        image_tensor = torch.from_numpy(image).unsqueeze(0)  # shape: (1, H, W)\n",
        "        image_tensor = (image_tensor / 127.5) - 1.0\n",
        "\n",
        "        # Retrieve label\n",
        "        label = self.labels[idx]\n",
        "        label_tensor = torch.from_numpy(label).float()  # shape: (2,)\n",
        "\n",
        "        return image_tensor, label_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b6c825",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "16b6c825",
        "outputId": "c177abc9-0869-4e5e-d47d-ea2db9f13ad6"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data_dir = '../dataset/DDIM_Generated_images/'\n",
        "dataset = ComplianceDataset(data_dir)\n",
        "\n",
        "# Visualize some images with compliance values\n",
        "num_samples = 5\n",
        "fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    image, label = dataset[i]\n",
        "    image = image.squeeze().numpy()  # Convert tensor to numpy array\n",
        "    comp1, comp2 = label.numpy()  # Retrieve compliance values\n",
        "\n",
        "    axes[i].imshow(image, cmap='gray')\n",
        "    axes[i].set_title(f\"C1: {comp1:.4f}\\nC2: {comp2:.4f}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GI1uggJtjTdl",
      "metadata": {
        "id": "GI1uggJtjTdl"
      },
      "source": [
        "## 3) Define CNN Model\n",
        "\n",
        "![CNN](https://drive.google.com/uc?id=11jjdlSmA0NxVcY2DyQeqIRZMrXyqyxC8)\n",
        "\n",
        "1. Uses three convolution layers (with max pooling) to reduce the input `(56×56)` down to `(7×7)` with 32 channels.\n",
        "2. Flattens the intermediate results and passes them through fully connected layers.\n",
        "3. Outputs two values for `(compliance1, compliance2)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z9dmpbAYDl6z",
      "metadata": {
        "id": "Z9dmpbAYDl6z"
      },
      "outputs": [],
      "source": [
        "class ComplianceCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1), # Extracts features using 8 filters of size 3×3.\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2), # Max-pooling with 2×2 window for downsampling\n",
        "\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(32 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)  # (compliance1, compliance2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lQb-qlOVjTdm",
      "metadata": {
        "id": "lQb-qlOVjTdm"
      },
      "source": [
        "## 4) Training Loop\n",
        "\n",
        "1. Create the dataset and split it into train & test sets.\n",
        "2. Create data loaders.\n",
        "3. Initialize the CNN model, criterion, optimizer, and learning rate scheduler.\n",
        "4. Train for a specified number of epochs, tracking training and testing loss.\n",
        "5. Save the model and a plot of the loss curves."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35da527f",
      "metadata": {
        "id": "35da527f"
      },
      "source": [
        "### **| Train / Test Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a69c19",
      "metadata": {
        "id": "a2a69c19"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def test(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UD67tqDS-jwT",
      "metadata": {
        "id": "UD67tqDS-jwT"
      },
      "source": [
        "### **| Set Up Training Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oDac8ync-jlF",
      "metadata": {
        "id": "oDac8ync-jlF"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "train_split = 0.8\n",
        "\n",
        "# Prepare Dataset & DataLoader\n",
        "full_dataset = ComplianceDataset(data_dir)\n",
        "dataset_len = len(full_dataset)\n",
        "train_len = int(dataset_len * train_split)\n",
        "test_len = dataset_len - train_len\n",
        "\n",
        "torch.manual_seed(1)\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_len, test_len], generator=torch.Generator().manual_seed(1))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UiepXrf3ALmA",
      "metadata": {
        "id": "UiepXrf3ALmA"
      },
      "source": [
        "### **| Initialize Model, Criterion, Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jDLcsQ9pAR4L",
      "metadata": {
        "id": "jDLcsQ9pAR4L"
      },
      "outputs": [],
      "source": [
        "learning_rate = 2e-3\n",
        "\n",
        "model = ComplianceCNN().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ajA4uYXU-uGy",
      "metadata": {
        "id": "ajA4uYXU-uGy"
      },
      "source": [
        "### **| Training Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4M2cuVHYjTdm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M2cuVHYjTdm",
        "outputId": "5c7f7e54-ee68-47f2-bbd9-03d4138def55"
      },
      "outputs": [],
      "source": [
        "epochs = 300\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    test_loss = test(model, test_loader, criterion, device)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}]  Train Loss: {train_loss:.6f}  Test Loss: {test_loss:.6f}\")\n",
        "    scheduler.step()\n",
        "\n",
        "# 5) Save Model & Loss\n",
        "os.makedirs('./model/best_model', exist_ok=True)\n",
        "torch.save(model.state_dict(), './model/best_model/Predictor_CNN.pth')\n",
        "\n",
        "os.makedirs('./model/loss_curves', exist_ok=True)\n",
        "print(\"Training complete. Model saved to ./model/best_model/Predictor_CNN.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f359500",
      "metadata": {
        "id": "4f359500"
      },
      "source": [
        "## 5) Visualize Training Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8d0edc5",
      "metadata": {
        "id": "a8d0edc5"
      },
      "source": [
        "### **| Loss Curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3599081a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "3599081a",
        "outputId": "270eb2f9-463f-4b93-e3d0-1a09d9be4cc5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(1, epochs + 1), train_losses, label='Train loss')\n",
        "plt.plot(range(1, epochs + 1), test_losses, label='Test loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0, 0.05)\n",
        "plt.title('Loss curves')\n",
        "plt.legend()\n",
        "plt.savefig('./model/loss_curves/loss_curve.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282cf42f",
      "metadata": {
        "id": "282cf42f"
      },
      "source": [
        "### **| Evaluate Metrics: RMSE, MAPE, R^2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4faf9eb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4faf9eb2",
        "outputId": "15fefccf-a5dc-4f18-abd9-fbcf484b12d9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "model.eval()\n",
        "y_true_1, y_pred_1 = [], []\n",
        "y_true_2, y_pred_2 = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)  # (batch, 2)\n",
        "        outputs = model(images)      # (batch, 2)\n",
        "\n",
        "        # Separate compliance1, compliance2\n",
        "        y_true_1.extend(labels[:, 0].cpu().numpy())\n",
        "        y_true_2.extend(labels[:, 1].cpu().numpy())\n",
        "        y_pred_1.extend(outputs[:, 0].cpu().numpy())\n",
        "        y_pred_2.extend(outputs[:, 1].cpu().numpy())\n",
        "\n",
        "def rmse(a, b):\n",
        "    return np.sqrt(mean_squared_error(a, b))\n",
        "\n",
        "def mape(a, b):\n",
        "    a, b = np.array(a), np.array(b)\n",
        "    return np.mean(np.abs((a - b) / a)) * 100\n",
        "\n",
        "y_true_1, y_pred_1 = np.array(y_true_1), np.array(y_pred_1)\n",
        "y_true_2, y_pred_2 = np.array(y_true_2), np.array(y_pred_2)\n",
        "\n",
        "compliance_min = np.array([29.07, 11.95])\n",
        "compliance_max = np.array([189.90, 191.65])\n",
        "\n",
        "y_true_1 = y_true_1 * (compliance_max[0] - compliance_min[0]) + compliance_min[0]\n",
        "y_pred_1 = y_pred_1 * (compliance_max[0] - compliance_min[0]) + compliance_min[0]\n",
        "\n",
        "y_true_2 = y_true_2 * (compliance_max[1] - compliance_min[1]) + compliance_min[1]\n",
        "y_pred_2 = y_pred_2 * (compliance_max[1] - compliance_min[1]) + compliance_min[1]\n",
        "\n",
        "rmse_1 = rmse(y_true_1, y_pred_1)\n",
        "mape_1 = mape(y_true_1, y_pred_1)\n",
        "r2_1 = r2_score(y_true_1, y_pred_1)\n",
        "\n",
        "rmse_2 = rmse(y_true_2, y_pred_2)\n",
        "mape_2 = mape(y_true_2, y_pred_2)\n",
        "r2_2 = r2_score(y_true_2, y_pred_2)\n",
        "\n",
        "print(f\"Compliance1  RMSE: {rmse_1:.4f}, MAPE: {mape_1:.2f}%, R²: {r2_1:.4f}\")\n",
        "print(f\"Compliance2  RMSE: {rmse_2:.4f}, MAPE: {mape_2:.2f}%, R²: {r2_2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a67ceae2",
      "metadata": {
        "id": "a67ceae2"
      },
      "source": [
        "### **| R^2 Plot (scatter of true vs. predicted)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd9ffc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5fd9ffc0",
        "outputId": "28b27705-d189-4365-ea44-081ff2dac349"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "axes[0].scatter(y_true_1, y_pred_1, c='blue', alpha=0.5, label='Compliance1')\n",
        "axes[0].plot([min(y_true_1), max(y_true_1)], [min(y_true_1), max(y_true_1)], 'r--')\n",
        "axes[0].set_title(f\"C1 R^2: {r2_1:.4f}\")\n",
        "axes[0].set_xlabel(\"True\")\n",
        "axes[0].set_ylabel(\"Predicted\")\n",
        "\n",
        "axes[1].scatter(y_true_2, y_pred_2, c='green', alpha=0.5, label='Compliance2')\n",
        "axes[1].plot([min(y_true_2), max(y_true_2)], [min(y_true_2), max(y_true_2)], 'r--')\n",
        "axes[1].set_title(f\"C2 R^2: {r2_2:.4f}\")\n",
        "axes[1].set_xlabel(\"True\")\n",
        "axes[1].set_ylabel(\"Predicted\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('./model/loss_curves/r2_scatter.png')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "name": "Predictor_CNN_Training"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
