{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smartdesignlab/SDL_teaching/blob/main/KAIST_SDL_3_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b50a07a",
      "metadata": {
        "id": "8b50a07a"
      },
      "source": [
        "# **3. Multi-Objective Optimization with Generative AI (DDIM) & Predictive AI (CNN) via NSGA-2**\n",
        "\n",
        "![](https://drive.google.com/uc?id=1IDICtMIUyU0ESoKNUOWMSZkiFVyuNZ51)\n",
        "\n",
        "- A **pre-trained CNN model** that predicts two compliance values (objectives).\n",
        "- A **pre-trained UNet model** with a DDIM scheduler for image generation.\n",
        "\n",
        "**Overview**:  \n",
        "1) Import libraries and set up environment.  \n",
        "2) Load pre-trained models (DDIM-based UNet & CNN predictor).  \n",
        "3) Generate structures from noise using DDIM.  \n",
        "4) Predict compliance values with CNN.  \n",
        "5) Optimize using NSGA-2.  \n",
        "6) Visualize and save results.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7c5e2a",
      "metadata": {
        "id": "7a7c5e2a"
      },
      "source": [
        "## 1) Import Libraries and Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34905cdc",
      "metadata": {
        "id": "34905cdc"
      },
      "source": [
        "### **| Load Pre-trained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc71d619",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc71d619",
        "outputId": "441ed7e3-6120-4b41-f848-24af1af1de95"
      },
      "outputs": [],
      "source": [
        "predictor_path = './model/Predictor_CNN.pth'\n",
        "generator_path = './model/Generator_DDIM.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89065875",
      "metadata": {
        "id": "89065875"
      },
      "source": [
        "### **| Import python libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95b9034",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "5e9d5110876e43afbb344c096e0939a4",
            "3bb3769baef547a1a487e9b8ab8e1b2e",
            "aa3847bb05814a629892b1100e68cf84",
            "c1bb6a1de8da443f9cd060cadaa33703",
            "c9d2506067e84caeb923a8ba7beebdd5",
            "0cb25d8e89c84e81bcbb661e1e1b837e",
            "be5f7ab3910b47d4bde269ef1b68f9c9",
            "1a190fe7a17d4885836a71f487a07ab0",
            "9e35ce688dc54a66a6325489de0a0711",
            "22e88d16a8c94afbb16f6bef9f0e48a9",
            "4ec5858658f246fea67db38ec197f079"
          ]
        },
        "id": "d95b9034",
        "outputId": "7558ae45-6089-4111-e7b1-6694949381c9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "from deap import base, creator, tools\n",
        "from diffusers import DDIMScheduler\n",
        "from diffusers.models import UNet2DModel\n",
        "\n",
        "# For inline image display (optional)\n",
        "from IPython.display import Image as DispImage, display\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device in use:\", device)\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Fix random seeds for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def sigmoid_filter(image: np.ndarray, alpha: float = 10.0):\n",
        "    image = (image + 1.0) / 2.0  # [-1, 1] → [0, 1]\n",
        "    contrasted = 1 / (1 + np.exp(-alpha * (image - 0.5)))\n",
        "    contrasted = (contrasted * 255).clip(0, 255).astype(np.uint8)\n",
        "    return contrasted"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fb14ce1",
      "metadata": {
        "id": "6fb14ce1"
      },
      "source": [
        "## 2) Load the Pre-trained Models\n",
        "### **| UNet (DDIM)**\n",
        "We load our DDIM-based generator (`UNet2DModel`) for reverse diffusion from noise to final structure. The scheduler is initialized using `DDIMScheduler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445ad2a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "445ad2a6",
        "outputId": "ff360cfd-0fd2-470f-a585-bfb35fa7aa77"
      },
      "outputs": [],
      "source": [
        "# Diffusion settings\n",
        "num_inference_steps = 50\n",
        "eta = 0.0\n",
        "\n",
        "# Load the UNet model\n",
        "unet = UNet2DModel(\n",
        "    sample_size=56,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    layers_per_block=1,\n",
        "    block_out_channels=[64, 128, 256, 512],\n",
        ").to(device)\n",
        "\n",
        "if os.path.exists(generator_path):\n",
        "    unet.load_state_dict(torch.load(generator_path, map_location=device))\n",
        "    print(f\"Model loaded from {generator_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Model file not found at {generator_path}\")\n",
        "\n",
        "# Initialize the DDIM scheduler\n",
        "scheduler = DDIMScheduler(num_train_timesteps=600)\n",
        "scheduler.set_timesteps(num_inference_steps, eta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4524c20b",
      "metadata": {
        "id": "4524c20b"
      },
      "source": [
        "### **| CNN Predictor**\n",
        "Our CNN model takes a **56x56** grayscale image as input and outputs two compliance values, `(Comp1, Comp2)`. The model is loaded from a saved `.pth` file. Adjust the checkpoint path as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ecd75c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ecd75c2",
        "outputId": "b194ff05-53c7-4827-d4a2-64c85f51957a"
      },
      "outputs": [],
      "source": [
        "class Predictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        # After three pooling layers, feature map size is (32, 7, 7)\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(32 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 2)  # (Compliance1, Compliance2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "# Load the pre-trained CNN\n",
        "predictor = Predictor().to(device)\n",
        "if os.path.exists(predictor_path):\n",
        "    predictor.load_state_dict(torch.load(predictor_path, map_location=device))\n",
        "    predictor.eval()\n",
        "    print(f\"Loaded compliance predictor from {predictor_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Predictor file not found at {predictor_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c3e0d1d",
      "metadata": {
        "id": "1c3e0d1d"
      },
      "source": [
        "## 3) Generation from Noise\n",
        "Given an input noise (size 56x56, range [-1,1]), we perform reverse diffusion steps to obtain the final structure via the UNet + DDIM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "205d1d7a",
      "metadata": {
        "id": "205d1d7a"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate_image_from_noise(noise: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    input: noise (1, 1, 56, 56)\n",
        "    return: generated image (1, 1, 56, 56)\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    for t in scheduler.timesteps:\n",
        "        t_tensor = torch.tensor(t, dtype=torch.long).to(device) # timestep -> torch long tensor\n",
        "        model_output = unet(noise, t_tensor).sample  # (B, 1, 56, 56)\n",
        "        noise = scheduler.step(model_output, t_tensor, noise).prev_sample # denoising step\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    return noise.clamp(-1.0, 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17aa9e40",
      "metadata": {
        "id": "17aa9e40"
      },
      "source": [
        "## 4) Evaluate Compliance via CNN\n",
        "The **evaluate_compliance** function:\n",
        "1. Converts a noise vector into a 2D noise tensor.\n",
        "2. Generates an image from noise using the UNet.\n",
        "3. Passes the generated image to our CNN `predictor`.\n",
        "4. Returns two compliance values `(comp1, comp2)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49d9dde4",
      "metadata": {
        "id": "49d9dde4"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_compliance(noise_vector: np.ndarray):\n",
        "    \"\"\"\n",
        "    Maps a noise vector to two compliance values via UNet + CNN.\n",
        "    noise_vector: NSGA-2 individual (gene) represented as noise in the range [-1, 1]\n",
        "    \"\"\"\n",
        "    # 1) Noise Vector -> Tensor\n",
        "    noise_tensor = torch.from_numpy(noise_vector).float().view(1, 1, 56, 56).to(device)\n",
        "\n",
        "    # 2) Generate image via DDIM\n",
        "    gen_image = generate_image_from_noise(noise_tensor)  # (1,1,56,56)\n",
        "\n",
        "    # 3) Predict compliance\n",
        "    comp_pred = predictor(gen_image)  # shape (1,2)\n",
        "    comp1_norm, comp2_norm = comp_pred[0, 0].item(), comp_pred[0, 1].item()\n",
        "\n",
        "    # 4) Denormalize (example scaling)\n",
        "    compliance_min = [29.07, 11.95]\n",
        "    compliance_max = [189.90, 191.65]\n",
        "\n",
        "    comp1 = comp1_norm * (compliance_max[0] - compliance_min[0]) + compliance_min[0]\n",
        "    comp2 = comp2_norm * (compliance_max[1] - compliance_min[1]) + compliance_min[1]\n",
        "\n",
        "    return (comp1, comp2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bad68dd5",
      "metadata": {
        "id": "bad68dd5"
      },
      "source": [
        "## 5) Multi-Objective Optimization using NSGA-2\n",
        "Below is the setup for our multi-objective optimization:\n",
        "1. **FitnessMin** (two objectives to minimize: compliance1, compliance2).\n",
        "2. **Individual** defined as a NumPy array of shape (56x56=3136,).\n",
        "3. Operators:\n",
        "   - **init_ind**: Random uniform initialization in [-1,1].\n",
        "   - **evaluate_compliance**: Our objective function.\n",
        "   - **mate**: We use `tools.cxBlend`.\n",
        "   - **mutate**: Gaussian mutation (`tools.mutGaussian`).\n",
        "4. **select**: We use NSGA-2 (`tools.selNSGA2`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd7446a4",
      "metadata": {
        "id": "bd7446a4"
      },
      "source": [
        "### **| Define Fitness, Individuals, and Toolbox python**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2718cf7c",
      "metadata": {
        "id": "2718cf7c"
      },
      "outputs": [],
      "source": [
        "# NSGA-2 parameters\n",
        "pop_size = 100   # Population size\n",
        "n_gen = 100      # Number of generations\n",
        "cxpb = 0.7       # Crossover probability\n",
        "mutpb = 0.5      # Mutation probability\n",
        "sigma = 0.3      # Mutation standard deviation\n",
        "\n",
        "# 1) Fitness and Individual definitions\n",
        "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0))  # minimize (comp1, comp2)\n",
        "creator.create(\"Individual\", np.ndarray, fitness=creator.FitnessMin) # individual definitions\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "\n",
        "# 2) Initialization function\n",
        "def init_ind(icls):\n",
        "    \"\"\"\n",
        "    Creates a single individual with random noise in [-1,1].\n",
        "    \"\"\"\n",
        "    array = np.random.uniform(-1, 1, size=(56*56,))\n",
        "    return icls(array)\n",
        "\n",
        "toolbox.register(\"individual\", init_ind, creator.Individual)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# 3) Objective function (CNN + DDIM)\n",
        "# This must be defined or imported:\n",
        "#   evaluate_compliance(ind)\n",
        "toolbox.register(\"evaluate\", evaluate_compliance)\n",
        "\n",
        "# 4) Crossover and mutation operators\n",
        "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5) # cxBlend\n",
        "# Add mutation noise to 5% of pixels based on 𝒩(0, 0.3²) distribution\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0.0, sigma=sigma, indpb=0.05)\n",
        "\n",
        "# 5) NSGA-2 selection\n",
        "toolbox.register(\"select\", tools.selNSGA2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f36ae81",
      "metadata": {
        "id": "5f36ae81"
      },
      "source": [
        "### **| Initialize and Evaluate Population**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb957d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbb957d5",
        "outputId": "9b4925e9-3761-4278-8512-8ca78162ed3b"
      },
      "outputs": [],
      "source": [
        "# 1) Create initial population\n",
        "pop = toolbox.population(n=pop_size)\n",
        "print(f\"Created initial population of size {pop_size}.\")\n",
        "\n",
        "# 2) Evaluate initial population\n",
        "invalid_ind = [ind for ind in pop if not ind.fitness.valid] # Select unevaluated individuals\n",
        "fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "for ind, fit in zip(invalid_ind, fitnesses):\n",
        "    ind.fitness.values = fit\n",
        "\n",
        "print(\"Initial population evaluated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YTXc59Jo-P3q",
      "metadata": {
        "id": "YTXc59Jo-P3q"
      },
      "source": [
        "### **| Preview Initial Structures Before Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737dee16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "737dee16",
        "outputId": "6d5d908d-dd66-457d-a992-24bcb32a8551"
      },
      "outputs": [],
      "source": [
        "num_samples = 10\n",
        "sample_population = pop[:num_samples]\n",
        "\n",
        "fig, axes = plt.subplots(2, num_samples, figsize=(num_samples * 2, 5))\n",
        "\n",
        "for i, ind in enumerate(sample_population):\n",
        "    noise_vector = ind.reshape(56, 56)\n",
        "    axes[0, i].imshow(noise_vector, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    axes[0, i].set_title(f\"Ind {i+1} (Noise)\", fontsize=10)\n",
        "    axes[0, i].axis(\"off\")\n",
        "\n",
        "    noise_tensor = torch.from_numpy(ind).float().view(1, 1, 56, 56).to(device)\n",
        "    gen_image = generate_image_from_noise(noise_tensor)\n",
        "    img_np = gen_image.squeeze().cpu().numpy()\n",
        "\n",
        "    filtered_img = sigmoid_filter(img_np)\n",
        "\n",
        "    axes[1, i].imshow(filtered_img, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    axes[1, i].set_title(f\"Ind {i+1} (Generated)\", fontsize=10)\n",
        "    axes[1, i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c0d1b4f",
      "metadata": {
        "id": "8c0d1b4f"
      },
      "source": [
        "### **| Multi-Objective Optimization: NSGA-2 Evolution Loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55d9e2b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55d9e2b8",
        "outputId": "4746bbf4-a980-48cd-af28-dab5bb37ea11"
      },
      "outputs": [],
      "source": [
        "for gen in range(n_gen):\n",
        "    print(f\"\\n-- Generation {gen+1} --\")\n",
        "\n",
        "    # 1) Selection\n",
        "    offspring = toolbox.select(pop, len(pop)) # Select top Pareto-ranked individuals (offspring)\n",
        "    offspring = list(map(toolbox.clone, offspring)) # Clone to preserve originals\n",
        "\n",
        "    # 2) Crossover\n",
        "    for i in range(0, len(offspring), 2):\n",
        "        if random.random() < cxpb and (i + 1) < len(offspring): # Apply crossover with probability cxpb\n",
        "            toolbox.mate(offspring[i], offspring[i + 1]) # Perform crossover on selected pair\n",
        "            del offspring[i].fitness.values # Delete fitness of first offspring\n",
        "            del offspring[i + 1].fitness.values # Delete fitness of second offspring\n",
        "\n",
        "    # 3) Mutation\n",
        "    for mutant in offspring:\n",
        "        if random.random() < mutpb: # Apply mutation with probability mutpb\n",
        "            toolbox.mutate(mutant) # Perform mutation on the individual\n",
        "            del mutant.fitness.values # Delete fitness after mutation\n",
        "\n",
        "    # 4) Re-evaluate invalid individuals\n",
        "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid] # Select individuals with invalid fitness\n",
        "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind) # Evaluate fitness for invalid individuals\n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "        ind.fitness.values = fit # Assign new fitness values\n",
        "\n",
        "    # 5) Combine parent + offspring, select next generation\n",
        "    pop = toolbox.select(pop + offspring, pop_size) # Combine parents and offspring, select top pop_size via NSGA-2\n",
        "\n",
        "    # Print generation results\n",
        "    fits = [ind.fitness.values for ind in pop]\n",
        "    for i, f in enumerate(fits):\n",
        "        print(f\"Individual {i} => (comp1={f[0]:.4f}, comp2={f[1]:.4f})\")\n",
        "\n",
        "print(\"\\nOptimization complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d432ffb4",
      "metadata": {
        "id": "d432ffb4"
      },
      "source": [
        "### **| Pareto Front**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c992f00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c992f00",
        "outputId": "ed0fc5a7-0da0-4423-85fc-1be98175fbd0"
      },
      "outputs": [],
      "source": [
        "fronts = tools.sortNondominated(pop, k=len(pop), first_front_only=True) # Adjustable, Select top 'k' Pareto front individuals for analysis\n",
        "pareto_front = fronts[0]\n",
        "pareto_front_sorted = sorted(pareto_front, key=lambda ind: ind.fitness.values[0])\n",
        "\n",
        "print(f\"Extracted Pareto front with {len(pareto_front_sorted)} individuals.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5349a11",
      "metadata": {
        "id": "d5349a11"
      },
      "source": [
        "### Save Pareto Front to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f224979",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f224979",
        "outputId": "c05d5732-1d87-45e3-aead-a50fb32d9c31"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"./model/final_results\", exist_ok=True)\n",
        "os.makedirs(\"./model/final_results/solutions\", exist_ok=True)\n",
        "\n",
        "csv_path = os.path.join(\"./model/final_results\", \"pareto_front.csv\")\n",
        "with open(csv_path, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Index\", \"Comp1\", \"Comp2\"])\n",
        "    for i, ind in enumerate(pareto_front_sorted):\n",
        "        comp1, comp2 = ind.fitness.values\n",
        "        writer.writerow([i + 1, comp1, comp2])\n",
        "\n",
        "print(f\"Pareto front CSV saved at: {csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f14fb88",
      "metadata": {
        "id": "4f14fb88"
      },
      "source": [
        "### Plot Pareto Front"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67f179f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "a67f179f",
        "outputId": "d69a07c7-30f9-4dcf-9133-0fb1d485fe42"
      },
      "outputs": [],
      "source": [
        "# Plot Pareto Front\n",
        "comp1_list = [ind.fitness.values[0] for ind in pareto_front]\n",
        "comp2_list = [ind.fitness.values[1] for ind in pareto_front]\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(comp1_list, comp2_list, c=\"blue\", alpha=0.7)\n",
        "plt.xlabel(\"Compliance1\")\n",
        "plt.ylabel(\"Compliance2\")\n",
        "plt.title(\"Pareto Front\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f12e61a",
      "metadata": {
        "id": "0f12e61a"
      },
      "source": [
        "### Pareto Solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfef64fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cfef64fa",
        "outputId": "b78ebd8c-bb53-4672-fcaf-e79ecfc23126"
      },
      "outputs": [],
      "source": [
        "grid_size = math.ceil(math.sqrt(len(pareto_front_sorted)))\n",
        "fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size * 2, grid_size * 2))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, ind in enumerate(pareto_front_sorted):\n",
        "    # Generate image from noise using UNet\n",
        "    noise_vector = torch.from_numpy(ind).float().view(1, 1, 56, 56).to(device)\n",
        "    gen_image = generate_image_from_noise(noise_vector) # Pareto front noise → Generate structure via DDIM\n",
        "    img_np = gen_image.squeeze().cpu().numpy()\n",
        "\n",
        "    # Apply sigmoid filter for better contrast\n",
        "    filtered_img = sigmoid_filter(img_np)\n",
        "\n",
        "    image_path = os.path.join(\"./model/final_results/solutions\", f\"solution_{idx+1}.png\")\n",
        "    plt.imsave(image_path, filtered_img, cmap=\"gray\")\n",
        "\n",
        "    # Plot the image\n",
        "    axes[idx].imshow(filtered_img, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    axes[idx].set_title(f\"C1: {ind.fitness.values[0]:.2f}, C2: {ind.fitness.values[1]:.2f}\", fontsize=8)\n",
        "    axes[idx].axis(\"off\")\n",
        "\n",
        "# Remove empty subplots\n",
        "for idx in range(len(pareto_front_sorted), len(axes)):\n",
        "    axes[idx].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "name": "DDIM_and_CNN_Optimization",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cb25d8e89c84e81bcbb661e1e1b837e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a190fe7a17d4885836a71f487a07ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "22e88d16a8c94afbb16f6bef9f0e48a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb3769baef547a1a487e9b8ab8e1b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cb25d8e89c84e81bcbb661e1e1b837e",
            "placeholder": "​",
            "style": "IPY_MODEL_be5f7ab3910b47d4bde269ef1b68f9c9",
            "value": ""
          }
        },
        "4ec5858658f246fea67db38ec197f079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e9d5110876e43afbb344c096e0939a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bb3769baef547a1a487e9b8ab8e1b2e",
              "IPY_MODEL_aa3847bb05814a629892b1100e68cf84",
              "IPY_MODEL_c1bb6a1de8da443f9cd060cadaa33703"
            ],
            "layout": "IPY_MODEL_c9d2506067e84caeb923a8ba7beebdd5"
          }
        },
        "9e35ce688dc54a66a6325489de0a0711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa3847bb05814a629892b1100e68cf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a190fe7a17d4885836a71f487a07ab0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e35ce688dc54a66a6325489de0a0711",
            "value": 0
          }
        },
        "be5f7ab3910b47d4bde269ef1b68f9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1bb6a1de8da443f9cd060cadaa33703": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e88d16a8c94afbb16f6bef9f0e48a9",
            "placeholder": "​",
            "style": "IPY_MODEL_4ec5858658f246fea67db38ec197f079",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "c9d2506067e84caeb923a8ba7beebdd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
